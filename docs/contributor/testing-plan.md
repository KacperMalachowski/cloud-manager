# Cloud Manager Testing Strategy Introduction Plan

### Purpose

The Cloud Manager module has reached maturity and is approaching production readiness. This means that ensuring quality is critical for an upcoming successful launch, extension, maintenance, and operation.

The purpose of this document is to establish guidelines for the testing approach, quality-oriented processes, and a quality-first mindset. To ensure the best quality for the module, it is necessary to establish pervasive practices that prioritize quality aspects throughout all stages of the software development life cycle.

### Audience

This document has two purposes. First, it is aimed at all members of the Kyma Leadership team who sponsor software engineering practices. Second, it is intended for the engineering team to prioritize their efforts in quality-enforcing activities.

The Kyma Leadership team can use this document to:
* Evaluate the functional readiness of the module.
* Approve the production readiness of the module.
* Ensure that the quality approach is aligned with the global Kyma vision.

The engineering team can use this document to:
* Prioritize their quality objectives.
* Define the quality baseline processes and practices.
* Agree on the list of quality metrics, their measurement functions, and target quality KPIs.

### Scope

The testing strategy for the Cloud Manager impacts the software development lifecycle of the engineering team. It clearly outlines the quality practices and expectations that should be incorporated into the engineering approach. The strategy also establishes a list of quality evidence artifacts that should be used to communicate the state of quality to all relevant stakeholders.

### Goal

The Cloud Manager testing strategy introduction plan is considered successful if it meets the following outcomes:
1. Creating the Cloud Manager testing strategy document based on the policies and objectives outlined in this plan.
2. Listing and systematizing the quality-related activities.
3. Measuring, assessing, and evaluating the quality aspects.
4. Generating quality evidence artifacts for the selected quality aspects.
5. Incorporating the quality-related practices into the development team's workflow.
6. Providing a communication mechanism for all relevant quality evidence artifacts to the relevant stakeholders.

### Roles and Responsibilities

The following is a summary of the roles and responsibilities involved in the testing strategy introduction plan:

| Stakeholder       | Quality Needs                                                | Responsibilities                                             |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Release Manager   | ● Ensures the release is ready based on the quality evidence.<br />● Ensures backward compatibility (via regression testing). | ● Defines the release-related quality objectives and policies.<br />● Assists in establishing a release procedure process by defining the quality evidence. |
|Release Master     | TBD                                                          |  TBD
| Product Owner     | ● Ensures all functional objectives are valid.<br />● Provides module validation and verification quality evidence. | ● Provides the list of acceptance criteria for every deliverable feature.<br />● Conducts feature acceptance using the quality evidence generated by an automated test suite using the acceptance criteria. |
| System Engineer   | ● Identifies the indicators that the system's design is controllable and not disrupted by new functionality. | ● Provides the architecture blueprints for the new functionality to fit the strategic vision. |
| Architect         | ● Defines the quality evidence for all non-functional quality aspects. | ● Defines the list of relevant non-functional requirements and the desired SLAs for them. |
| Quality Assurance | ● Ensures that there is measurable evidence that the processes and product's quality-related aspects are controllable. | ● Outlines quality-related processes and activities.<br />● Defines the testing strategy and testing plan documents to provide the means of reaching the quality objectives. |
| Developers        | ● Ensures engineering processes are maintainable and repeatable to provide a deliverable product in a consistent manner.<br />● Establish quality gates that provide confidence in the sufficient stability of the deliverable piece of implementation. | ● Defines Code of Conduct documents for engineering activities.<br />● Adhere to practices and activities defined in the testing strategy and testing policy documents.<br />● Contribute to the quality-first approach in every activity. |
| Technical Writers | ● Ensures traceability in the product evolution to adjust the user-facing and technical documentation to the latest product state. | ● Base documentation-related activities on the acceptance criteria and architecture blueprints artifacts. |

### The Plan

#### The Kickoff Phase

The first phase of creating a testing strategy involves aligning with relevant stakeholders to adjust the quality needs. During this phase, responsibilities for each role must be assigned, and the testing strategy document must be created consolidating all the decisions and agreements made. The following tasks must be carried out in this phase:

- [ ] Identify all relevant stakeholders and their quality needs.
- [ ] Adjust the responsibilities based on the aforementioned quality needs.
- [ ] Identify the alterations required for existing development processes and activities to factor in the quality needs.
- [ ] Consolidate all the quality needs and the means to achieve them in the testing strategy document.

#### The Inception Phase

Perform a due diligence audit of the existing software development processes and activities based on the testing strategy document. The audit aims to identify any additional gaps and inefficiencies in the current development process missed during the kickoff phase, and define corrective actions to address them:

- [ ] Prepare a due diligence audit checklist to identify any gaps and inefficiencies in the software development process.
- [ ] Conduct a due diligence audit for the existing development process.
- [ ] Based on the results of the audit process, define any missing activities, processes, and documents.
- [ ] Create a groomed backlog of corrective actions.
- [ ] Prioritize and brainstorm the optimal sequence for incorporating the corrective actions.

#### The Integration Phase

Iterate over the backlog of the corrective actions and integrate them into the engineering process:

- [ ] Pick the most relevant corrective action from the backlog and incorporate it into the engineering process.
- [ ] Notify the relevant stakeholders about the quality evidence that has been added and establish a mechanism for automatic notification.
- [ ] Iterate over all corrective actions agreed upon.

#### The Continuous Improvements Phase

After implementing all necessary corrective actions, it is important to conduct a regular audit to ensure that the agreed-upon practices, policies, and objectives are followed. The following steps must be taken:

- [ ] Conduct the regular audit.
- [ ] Reflect on the results of the audit and determine if any additional corrective actions are needed.
- [ ] Brainstorm on how to add more quality attributes and activities.

### Schedule

**TBD.** To define this section, we must agree on the proposal outlined in this document, assess our development budget, and devise feasible timelines for each phase, breaking it down into smaller steps. A Gantt diagram with milestones and timelines will also be needed.

## Appendix A. Quality Strategy Document

The testing strategy involves addressing and incorporating functional and non-functional requirements, processes, and practices to meet the expected quality standards. The testing strategy document must include the following:

- [ ] **Testing approach**. This specifies the amount of automated, manual, exploratory, penetration, and performance testing required to attain the quality objectives.
- [ ] **Testing levels**. This outlines the unit, integration, system, acceptance, end-to-end test suites, their intention, and the reasons behind each test suite. It also includes an approach to avoid over-testing and overspecification.
- [ ] **Testing types**. This describes the functional and non-functional tests, their granularity, and their purpose, mapped to the relevant quality objectives.
- [ ] **Level of detail**. This defines the boundaries and responsibilities of each test suite.
- [ ] **Testing tools**. This outlines the tools, frameworks and platforms to be used for testing.
- [ ] **Test deliverables**. This includes the artifacts and documents required to be produced during the testing process to communicate the progress and findings of testing activities.
- [ ] **Testing measurements and metrics**. This establishes the key performance indicators (KPI) and success metrics for the project.
- [ ] **Risk assessment**. This lists out the potential risks and clear plans to mitigate them, or even contingency plans to adopt in case these risks do show up in reality.

## Appendix B. Quality Evidence Artefacts

This section presents a draft list of quality evidence artifacts that can be created using quality-oriented activities.

| Artefact                     | Links                                                        |
| ---------------------------- | ------------------------------------------------------------ |
| Unit test coverage           | ● Unit test coverage expectation document<br />● Unit test coverage report |
| Functional correctness       | ● The functional/acceptance testing report<br />● Functional testing approach outline |
| Functional completeness      | ● Coverage analysis of functional aspects by the acceptance test suite |
| Performance                  | ● Module expected Service Level Agreements (SLAs) <br />● Performance testing strategy and approach<br />● Performance testing report which includes time behaviour and resource utilization |
| Maintainability & Modularity | ● Code review code of conduct <br />● Code-style agreement<br />● Project structure description<br />● Modular metrics and expectations |
| Reusability                  | ● TBD. How reusable is the codebase?                         |
| Testability                  | ● TBD. How Testable os the codebase?                         |
| Interoperability             | ● Supported cloud providers list<br />                       |
| Faultlessness                | ● The report with the trend of the Mean Time Between Failures (MTBF) <br /> |
| TBD...                       |                                                              |

## Appendix C. Supplementary Documents

This section outlines supplementary documents aimed at improving the quality of the engineering process.

| Aspect               | Document                            | Purpose                                                      |
| -------------------- | ----------------------------------- | ------------------------------------------------------------ |
| Software Engineering | Code Style Code of Conduct          | This document defines the coding baseline for the software engineering activities. |
| Software Engineering | Code Review Code of Conduct         | This document outlines the baseline expectations for the code-review process, including which test suites are mandatory and which are optional, the necessity of system diagrams for architectural changes, and more... |
| Software Engineering | Project Structure                   | This document includes the agreement on the architecture and structure of the project. |
| Monitoring           | The metrics generated by the module | This document outlines the observation-critical metrics to be used for monitoring the module. |
| Integration Testing  | External dependencies isolation     | This document outlines the approach to replace third-party dependencies with controllable test-doubles. |