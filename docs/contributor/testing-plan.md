# Cloud Manager Testing Strategy Introduction Plan

### Purpose

The Cloud Manager component has reached maturity and is approaching production readiness. This means that ensuring quality is critical for an upcoming successful launch, extension, maintenance, and operation.

The purpose of this document is to establish guidelines for the testing approach, quality-oriented processes, and a quality-first mindset. To ensure the best quality for the component, it is necessary to establish pervasive practices that prioritise quality aspects throughout all stages of the software development life cycle.

### Audience

This document has two purposes. First, it is aimed at all members of the Kyma Leadership team who sponsor software engineering practices. Second, it is intended for the engineering team to prioritize their efforts in quality-enforcing activities.

The Kyma Leadership team can use this document to:
* Evaluate the functional readiness of the module.
* Approve the production readiness of the module.
* Ensure that the quality approach is aligned with the global Kyma vision.

The engineering team can use this document to:
* Prioritise their quality objectives.
* Define the quality baseline processes and practices.
* Agree on the list of quality metrics, their measurement functions, and target quality KPIs.

### Scope

The Testing Strategy for the Cloud Manager will have an impact on the software development life cycle of the engineering team. It will provide a clear outline of the quality practices and expectations that should be incorporated in the engineering approach. The strategy will also establish a list of quality evidence artifacts which should be used to communicate the state of quality to all relevant stakeholders.

### Goal

The Cloud Manager Testing Strategy Introduction Plan document will be considered successful if it meets the following outcomes:
1. Creating the Cloud Manager Testing Strategy document based on the policies and objectives outlined in this plan.
2. Listing and systematising the quality-related activities.
3. Measuring, assessing and evaluating the quality aspects.
4. Generating quality evidence artifacts for the selected quality aspects.
5. Incorporating the quality-related practices into the development team's workflow.
6. Providing a communication mechanism for all relevant quality evidence artifacts to the relevant stakeholders.

### Roles and Responsibilities

The following is a summary of the roles and responsibilities involved in the Testing Strategy introduction plan:

| Stakeholder       | Quality Needs                                                | Responsibilities                                             |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Release Manager   | ● Ensure that the release is ready based on the quality evidence.<br />● Ensure backward compatibility (via regression testing). | ● Define the release-related quality objectives and policies.<br />● Assist in establishing a release procedure process by defining the quality evidence. |
|Release Master     | TBD                                                          |  TBD
| Product Owner     | ● Ensure that all functional objectives are valid.<br />● Provide module validation and verification quality evidence. | ● Provide the list of acceptance criteria for every deliverable feature.<br />● Conduct feature acceptance using the quality evidence generated by an automated test suite using the acceptance criteria. |
| System Engineer   | ● Identify the indicators that the system's design is controllable and not disrupted by new functionality. | ● Provide the architecture blueprints for the new functionality to fit the strategic vision. |
| Architect         | ● Define the quality evidence for all non-functional quality aspects. | ● Define the list of relevant non-functional requirements and the desired SLAs for them. |
| Quality Assurance | ● Ensure that there is measurable evidence that the processes and product's quality-related aspects are controllable. | ● Outline quality-related processes and activities.<br />● Define the Testing Strategy and Testing Plan documents to provide the means of reaching the quality objectives. |
| Developers        | ● Ensure that engineering processes are maintainable and repeatable to provide a deliverable product in a consistent manner.<br />● Establish quality gates that provide confidence in the sufficient stability of the deliverable piece of implementation. | ● Define Code of Conduct documents for engineering activities.<br />● Adhere to practices and activities defined in the Testing Strategy and Testing Policy documents.<br />● Contribute to the quality-first approach in every activity. |
| Technical Writers | ● Ensure traceability in the product evolution to adjust the user-facing and technical documentation to the latest product state. | ● Base documentation-related activities on the acceptance criteria and architecture blueprints artifacts. |

### The Plan

#### The Kickoff Phase

The first phase of creating a Testing Strategy involves aligning with relevant stakeholders to adjust the quality needs. During this phase, responsibilities for each role need to be assigned, and a Testing Strategy document needs to be created consolidating all the decisions and agreements made. The following tasks need to be carried out in this phase:

- [ ] Identify all relevant stakeholders and their quality needs.
- [ ] Adjust the responsibilities based on the aforementioned quality needs.
- [ ] Identify the alterations required for existing development processes and activities to factor in the quality needs.
- [ ] Consolidate all the quality needs and the means to achieve them in the Testing Strategy document.

#### The Inception Phase

Perform a due-diligence audit of the existing software development processes and activities based on the Testing Strategy document. The audit aims to identify any additional gaps and inefficiencies in the current development process missed during the Kickoff phase, and define corrective actions to address them:

- [ ] Prepare a due-diligence audit checklist to identify any gaps and inefficiencies in the software development process.
- [ ] Conduct a due-diligence audit for the existing development process.
- [ ] Based on the results of the audit process, define any missing activities, processes, and documents.
- [ ] Create a groomed backlog of corrective actions.
- [ ] Prioritize and brainstorm the optimal sequence for incorporating the corrective actions.

#### The Integration Phase

Iterate over the backlog of the corrective actions and integrate them into the engineering process:

- [ ] Pick the most relevant corrective action from the backlog and incorporate it into the engineering process.
- [ ] Notify the relevant stakeholders about the quality evidence that has been added and establish a mechanism for automatic notification.
- [ ] Iterate over all corrective actions agreed upon.

#### The Continuous Improvements Phase

fter implementing all necessary corrective actions, it is important to conduct a regular audit to ensure that the agreed-upon practices, policies, and objectives continue to be followed. The following steps should be taken:

- [ ] Conduct the regular audit.
- [ ] Reflect on the results of the audit and determine if any additional corrective actions are needed.
- [ ] Brainstorm on how to add more quality attributes and activities.

### Schedule

**TBD.** To define this section, we need to agree on the proposal outlined in this document, assess our development budget, and devise feasible timelines for each phase, breaking it down into smaller steps. A Gantt diagram with milestones and timelines will also be needed.

## Appendix A. Quality Strategy Document

The testing strategy involves addressing and incorporating functional and non-functional requirements, processes, and practices to meet the expected quality standards. The Testing Strategy document should include the following:

- [ ] **Testing approach**. This specifies the amount of automated, manual, exploratory, penetration, and performance testing required to attain the quality objectives.
- [ ] **Testing levels**. This outlines the unit, integration, system, acceptance, and end-to-end test suites, their intention, and the reasons behind each test suite. It also includes an approach to avoid over-testing and overspecification.
- [ ] **Testing types**. This describes the functional and non-functional tests, their granularity, and their purpose, mapped to the relevant quality objectives.
- [ ] **Level of detail**. This defines the boundaries and responsibilities of each test suite.
- [ ] **Testing tools**. This outlines the tools, frameworks and platforms to be used for testing.
- [ ] **Test deliverables**. This includes the artifacts and documents required to produce during the testing process to communicate the progress and findings of testing activities.
- [ ] **Testing measurements and metrics**. This establishes the key performance indicators (KPI) and success metrics for the project.
- [ ] **Risk assessment**. This lists out the potential risks and clear plans to mitigate them, or even contingency plans to adopt in case these risks do show up in reality.

## Appendix B. Quality Evidence Artefacts

This section presents a draft list of quality evidence artifacts that can be created using quality-oriented activities.

| Artefact                     | Links                                                        |
| ---------------------------- | ------------------------------------------------------------ |
| Unit test coverage           | ● Unit test coverage expectation document<br />● Unit test coverage report |
| Functional correctness       | ● The functional/acceptance testing report<br />● Functional testing approach outline |
| Functional completeness      | ● Coverage analysis of functional aspects by the acceptance test suite |
| Performance                  | ● Module expected Service Level Agreements (SLAs) <br />● Performance testing strategy and approach<br />● Performance testing report which includes time behaviour and resource utilisation |
| Maintainability & Modularity | ● Code review code of conduct <br />● Code-style agreement<br />● Project structure description<br />● Modular metrics and expectations |
| Reusability                  | ● TBD. How reusable is the codebase?                         |
| Testability                  | ● TBD. How Testable os the codebase?                         |
| Interoperability             | ● Supported cloud providers list<br />                       |
| Faultlessness                | ● The report with the trend of the Mean Time Between Failures (MTBF) <br /> |
| TBD...                       |                                                              |

## Appendix C. Supplementary Documents

This section outlines supplementary documents aimed at improving the quality of the engineering process.

| Aspect               | Document                            | Purpose                                                      |
| -------------------- | ----------------------------------- | ------------------------------------------------------------ |
| Software Engineering | Code Style Code of Conduct          | This document defines the coding baseline for the software engineering activities. |
| Software Engineering | Code Review Code of Conduct         | This document outlines the baseline expectations for the code-review process, including which test suites are mandatory and which are optional, the necessity of system diagrams for architectural changes, and more... |
| Software Engineering | Project Structure                   | This document includes the agreement on the architecture and structure of the project. |
| Monitoring           | The metrics generated by the module | This document outlines the observation-critical metrics to be used for monitoring the module. |
| Integration Testing  | External dependencies isolation     | This document outlines the approach to replace third-party dependencies with controllable test-doubles. |